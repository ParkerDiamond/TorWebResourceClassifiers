{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Input to Tor Web Resource Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jms/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import random\n",
    "random = random.SystemRandom(SEED)\n",
    "\n",
    "from copy import deepcopy\n",
    "from os.path import join\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pycm import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(all_resources, accessed_resources, total_size):\n",
    "\n",
    "    datapoints = np.zeros(shape=(total_size, len(all_resources)), dtype=int)\n",
    "\n",
    "    labels = np.array([])\n",
    "    label_nums = np.array([], dtype=int)\n",
    "    resources_arr = np.array(all_resources)\n",
    "\n",
    "    # we want to iterate trough all the resources\n",
    "    # and create boolean matrix in which each row\n",
    "    # corresponds to which resources were requested\n",
    "    # while loading a page that is our label\n",
    "\n",
    "    index = 0\n",
    "    count = 0\n",
    "    for label, resources_groups in accessed_resources.items():\n",
    "\n",
    "        rows_num = len(resources_groups)\n",
    "\n",
    "        # we want to avoid rows that have all the 0s\n",
    "        for i in range(rows_num):\n",
    "            datapoints[i+index] = np.in1d(resources_arr, resources_groups[i]).astype(int)\n",
    "\n",
    "        labels = np.append(labels, np.full((1, rows_num), label))\n",
    "        label_nums = np.append(label_nums, np.full((1, rows_num), count))\n",
    "\n",
    "\n",
    "        # print(\"Rows for \", label,\" - \", count, \" created; \", rows_num, \" rows were added\")\n",
    "\n",
    "        count += 1\n",
    "        index += rows_num\n",
    "\n",
    "    # got the boolean matrix, now call function that processes it\n",
    "\n",
    "    print('Matrix is created...')\n",
    "    return datapoints, label_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_dir(path, mode, clf=None):\n",
    "    dirs = listdir(path)\n",
    "\n",
    "    accessed_resources = {}\n",
    "    all_resources = set()\n",
    "    total_size = 0\n",
    "\n",
    "    for dir in dirs:\n",
    "        newpath = join(path, dir)\n",
    "        files = listdir(newpath)\n",
    "\n",
    "        # get the name of the file which contains requested resources\n",
    "        # strip .txt to save it as label for classification\n",
    "        # create path name to access the file\n",
    "\n",
    "        for file in files:\n",
    "            filepath = join(newpath,file)\n",
    "            if os.stat(filepath).st_size == 0:\n",
    "                continue\n",
    "\n",
    "            r_list = []\n",
    "            key = file[:-4]\n",
    "\n",
    "            if key[0:3] == 'www':\n",
    "                key = key[4:]\n",
    "\n",
    "            if not bool(accessed_resources.get(key)):\n",
    "                accessed_resources[key] = []\n",
    "            lines = [line.rstrip('\\n') for line in open(filepath)]\n",
    "\n",
    "            # each line has hostname and ip address\n",
    "            # we only need hostname and we want to strip 'www.'\n",
    "            # we add each resource to the overall set of resources ever accessed +\n",
    "            # we add resources for current key to be added to hash table later by key\n",
    "\n",
    "            tld = key.split('.')[0]\n",
    "\n",
    "            for line in lines:\n",
    "                requested_resource = line.split(',')[0]\n",
    "                if (mode == \"nontld\" and tld in line) or (mode == \"tld\" and tld not in line):\n",
    "                    continue\n",
    "                if requested_resource[0:3] == 'www':\n",
    "                    requested_resource = requested_resource[4:]\n",
    "                all_resources.add(requested_resource)\n",
    "                r_list.append(requested_resource)\n",
    "\n",
    "            # we want to crate a row only if has at least one '1'\n",
    "            # If list of resources is empty than there will no such thing\n",
    "\n",
    "            if r_list:\n",
    "                accessed_resources[key].append(r_list)\n",
    "                total_size += 1\n",
    "\n",
    "    print('Files are processed...')\n",
    "    return list(all_resources), accessed_resources, total_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_adv_noise(accessed_resources, adv_mode, adv_min, adv_max):\n",
    "    if adv_mode is None:\n",
    "        return accessed_resources\n",
    "    \n",
    "    # Insert noise based on adv_mode\n",
    "    new_accessed_resources = {}\n",
    "    \n",
    "    num_to_add = random.randint(adv_min, adv_max)\n",
    "    print(\"Number of domains to add: {}\".format(num_to_add))\n",
    "    \n",
    "    for i, (site, resources_loaded_per_domain) in enumerate(accessed_resources.items()):\n",
    "        if adv_mode == \"random_internal\":\n",
    "            new_resources_loaded_per_domain = []\n",
    "            # print(\"Adding {} resources to every {} list\".format(num_to_add, site))\n",
    "            \n",
    "            for domain_resources in resources_loaded_per_domain:\n",
    "                new_resources = deepcopy(domain_resources)\n",
    "                \n",
    "                idx = 0\n",
    "                while idx < num_to_add:\n",
    "                    new_resource_choice = random.choice(all_resources)\n",
    "                    if new_resource_choice not in new_resources:\n",
    "                        new_resources.append(new_resource_choice)\n",
    "                        idx += 1\n",
    "                new_resources_loaded_per_domain.append(new_resources)\n",
    "            \n",
    "            new_accessed_resources[site] = new_resources_loaded_per_domain\n",
    "        elif adv_mode == \"disjoint_domain\":\n",
    "            new_resources_loaded_per_domain = []\n",
    "            this_domain_unique_resources = list(set([x for xs in accessed_resources[site] for x in xs]))\n",
    "            \n",
    "            for domain_resources in resources_loaded_per_domain:\n",
    "                new_resources = deepcopy(domain_resources)\n",
    "                \n",
    "                idx = 0\n",
    "                while idx < num_to_add:\n",
    "                    new_resource_choice = random.choice(all_resources)\n",
    "                    if new_resource_choice not in new_resources and new_resource_choice not in this_domain_unique_resources:\n",
    "                        new_resources.append(new_resource_choice)\n",
    "                        idx += 1\n",
    "                \n",
    "                new_resources_loaded_per_domain.append(new_resources)\n",
    "            new_accessed_resources[site] = new_resources_loaded_per_domain\n",
    "        else:\n",
    "            raise ValueError(\"Not implemented yet!\")\n",
    "            \n",
    "    return new_accessed_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Adversarial Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of None, random_internal, disjoint_domain, disjoint_exit\n",
    "adv_mode = \"disjoint_domain\"\n",
    "\n",
    "# Range of resources to add to each sample\n",
    "# Chosen randomly and uniform across all samples once a number is chosen\n",
    "adv_min = 50\n",
    "adv_max = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are processed...\n"
     ]
    }
   ],
   "source": [
    "all_resources, accessed_resources, total_size = read_from_dir(\"../opt/tor_alexa_resolutions\", \"tld\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the New Dataset with or without Adversarial Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of domains to add: 82\n"
     ]
    }
   ],
   "source": [
    "new_accessed_resources = add_adv_noise(accessed_resources, adv_mode, adv_min, adv_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix is created...\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_matrix(list(all_resources), new_accessed_resources, total_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished splitting data!\n"
     ]
    }
   ],
   "source": [
    "method = \"mlp\"\n",
    "\n",
    "X = X.astype(float)\n",
    "\n",
    "train_f, test_f, train_l, test_l = train_test_split(\n",
    "    X, Y, test_size=0.35, random_state=56)\n",
    "\n",
    "print(\"Finished splitting data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the classifier\n",
    "clf = LinearSVC()\n",
    "\n",
    "if method == 'mlp':\n",
    "    clf = MLPClassifier(batch_size=1000, random_state=SEED)\n",
    "elif method == 'forest':\n",
    "    clf = RandomForestClassifier()\n",
    "elif method != 'svc':\n",
    "    print('Specify another method: \"svm\", \"mlp\" or \"forrest\"')\n",
    "    raise ValueError(\"Invalid choice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 1464.1755030155182\n",
      "Fitting is done!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf.fit(train_f, train_l)\n",
    "end = time.time()\n",
    "elapsed_fit_time = end - start\n",
    "print(\"Fit time: {}\".format(elapsed_fit_time))\n",
    "print('Fitting is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time: 2.2373197078704834\n",
      "Testing is done!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_true, y_pred = test_l, clf.predict(test_f)\n",
    "end = time.time()\n",
    "elapsed_predict_time = end - start\n",
    "print(\"Test time: {}\".format(elapsed_predict_time))\n",
    "print('Testing is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the PyCM library: https://github.com/sepandhaghighi/pycm\n",
    "\n",
    "Docs on it here: http://www.shaghighi.ir/pycm/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=y_true, predict_vector=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cm.overall_stat\n",
    "df = pd.DataFrame.from_dict(d, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall_ACC</th>\n",
       "      <td>0.209654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa</th>\n",
       "      <td>0.208809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall_RACC</th>\n",
       "      <td>0.00106825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strength_Of_Agreement(Landis and Koch)</th>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strength_Of_Agreement(Fleiss)</th>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strength_Of_Agreement(Altman)</th>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strength_Of_Agreement(Cicchetti)</th>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR_Macro</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV_Macro</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR_Micro</th>\n",
       "      <td>0.209654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV_Micro</th>\n",
       "      <td>0.209654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott_PI</th>\n",
       "      <td>0.208792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gwet_AC1</th>\n",
       "      <td>0.208836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bennett_S</th>\n",
       "      <td>0.208836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa Standard Error</th>\n",
       "      <td>0.00225737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa 95% CI</th>\n",
       "      <td>(0.2043845222610521, 0.21323340392071724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi-Squared</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-Squared</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cramer_V</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi-Squared DF</th>\n",
       "      <td>933156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95% CI</th>\n",
       "      <td>(0.2052344421649936, 0.21407387096600955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard Error</th>\n",
       "      <td>0.00225496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response Entropy</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reference Entropy</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross Entropy</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joint Entropy</th>\n",
       "      <td>14.1933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conditional Entropy</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Divergence</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lambda B</th>\n",
       "      <td>0.214872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lambda A</th>\n",
       "      <td>0.214876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa Unbiased</th>\n",
       "      <td>0.208792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall_RACCU</th>\n",
       "      <td>0.00108919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kappa No Prevalence</th>\n",
       "      <td>-0.580692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mutual Information</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall_J</th>\n",
       "      <td>(128.3403366799359, 0.1327200999792512)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hamming Loss</th>\n",
       "      <td>0.790346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero-one Loss</th>\n",
       "      <td>25755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIR</th>\n",
       "      <td>0.00159573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-Value</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                0\n",
       "Overall_ACC                                                              0.209654\n",
       "Kappa                                                                    0.208809\n",
       "Overall_RACC                                                           0.00106825\n",
       "Strength_Of_Agreement(Landis and Koch)                                       Fair\n",
       "Strength_Of_Agreement(Fleiss)                                                Poor\n",
       "Strength_Of_Agreement(Altman)                                                Fair\n",
       "Strength_Of_Agreement(Cicchetti)                                             Poor\n",
       "TPR_Macro                                                                    None\n",
       "PPV_Macro                                                                    None\n",
       "TPR_Micro                                                                0.209654\n",
       "PPV_Micro                                                                0.209654\n",
       "Scott_PI                                                                 0.208792\n",
       "Gwet_AC1                                                                 0.208836\n",
       "Bennett_S                                                                0.208836\n",
       "Kappa Standard Error                                                   0.00225737\n",
       "Kappa 95% CI                            (0.2043845222610521, 0.21323340392071724)\n",
       "Chi-Squared                                                                  None\n",
       "Phi-Squared                                                                  None\n",
       "Cramer_V                                                                     None\n",
       "Chi-Squared DF                                                             933156\n",
       "95% CI                                  (0.2052344421649936, 0.21407387096600955)\n",
       "Standard Error                                                         0.00225496\n",
       "Response Entropy                                                             None\n",
       "Reference Entropy                                                            None\n",
       "Cross Entropy                                                                None\n",
       "Joint Entropy                                                             14.1933\n",
       "Conditional Entropy                                                          None\n",
       "KL Divergence                                                                None\n",
       "Lambda B                                                                 0.214872\n",
       "Lambda A                                                                 0.214876\n",
       "Kappa Unbiased                                                           0.208792\n",
       "Overall_RACCU                                                          0.00108919\n",
       "Kappa No Prevalence                                                     -0.580692\n",
       "Mutual Information                                                           None\n",
       "Overall_J                                 (128.3403366799359, 0.1327200999792512)\n",
       "Hamming Loss                                                             0.790346\n",
       "Zero-one Loss                                                               25755\n",
       "NIR                                                                    0.00159573\n",
       "P-Value                                                                      None"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function modified to plot the ConfusionMatrix object.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    Code Reference : \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    plt_cm = []\n",
    "    for i in cm.classes:\n",
    "        row=[]\n",
    "        for j in cm.classes:\n",
    "            row.append(cm.table[i][j])\n",
    "        plt_cm.append(row)\n",
    "    plt_cm = np.array(plt_cm)\n",
    "    if normalize:\n",
    "        plt_cm = plt_cm.astype('float') / plt_cm.sum(axis=1)[:, np.newaxis]     \n",
    "    plt.imshow(plt_cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(cm.classes))\n",
    "    plt.xticks(tick_marks, cm.classes, rotation=45)\n",
    "    plt.yticks(tick_marks, cm.classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = plt_cm.max() / 2.\n",
    "    for i, j in itertools.product(range(plt_cm.shape[0]), range(plt_cm.shape[1])):\n",
    "        plt.text(j, i, format(plt_cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if plt_cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
